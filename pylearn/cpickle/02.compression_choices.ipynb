{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's use three popular algoritms\n",
    "\n",
    "- [bzip2](https://docs.python.org/3/library/bz2.html)\n",
    "- [gzip](https://docs.python.org/3/library/gzip.html)\n",
    "- [blosc2](https://github.com/Blosc/python-blosc2)\n",
    "\n",
    "Blosc is a high performance compressor optimized for binary data (i.e. floating point numbers, integers and booleans, although it can handle string data too). I\n",
    "\n",
    "\"\"\"\n",
    "import bz2, gzip, blosc2\n",
    "import _pickle as cPickle\n",
    "import pickle\n",
    "import pandas\n",
    "\n",
    "def plain_load(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "      return cPickle.load(f)\n",
    "\n",
    "def pandas_load(file):\n",
    "    df = pandas.read_csv(file)\n",
    "    return df\n",
    "\n",
    "def plain_dump(file, data):\n",
    "    with open(file, \"wb\") as f:\n",
    "      return cPickle.dump(data,f)\n",
    "\n",
    "\n",
    "def compress_pickle_b2z(file, data):\n",
    "    with bz2.BZ2File(file, 'wb') as f:\n",
    "        cPickle.dump(data, f)\n",
    "\n",
    "def decompress_pickle_b2z(file):\n",
    "    data = bz2.BZ2File(file, 'rb')\n",
    "    return cPickle.load(data)\n",
    "\n",
    "\n",
    "def decompress_pickle_gzip(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return cPickle.loads(gzip.decompress(f.read()))\n",
    "\n",
    "def compress_pickle_gzip(file, data):\n",
    "    with open(file, 'wb') as f:\n",
    "        f.write(gzip.compress(cPickle.dumps(data)))\n",
    "\n",
    "\n",
    "def decompress_pickle_blosc2(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return cPickle.loads(blosc2.decompress(f.read()))\n",
    "\n",
    "def compress_pickle_blosc2(file, data):\n",
    "    blosc2.MAX_BUFFERSIZE = 8 * 1024 * 1024 * 1024\n",
    "    with open(file, 'wb') as f:\n",
    "        f.write(blosc2.compress(cPickle.dumps(data)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's compress using our three formats\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = plain_load('../data/customers-100000.pickle')\n",
    "\n",
    "compress_pickle_b2z(\"../data/customers-100000.pbz2\", df)\n",
    "compress_pickle_gzip(\"../data/customers-100000.gzip\", df)\n",
    "compress_pickle_blosc2(\"../data/customers-100000.blosc2\", df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307 ms ± 12.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.27 s ± 30.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "174 ms ± 8.67 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit decompress_pickle_gzip(\"../data/customers-100000.gzip\")\n",
    "%timeit decompress_pickle_b2z(\"../data/customers-100000.pbz2\")\n",
    "%timeit decompress_pickle_blosc2(\"../data/customers-100000.blosc2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "any of the three files can be used to restore the pandas dataframe\n",
    "\n",
    "\"\"\"\n",
    "df = decompress_pickle_gzip(\"../data/customers-100000.gzip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's compare file sizes, and compression rates\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "class PerformanceStats:\n",
    "    def __init__(self, filename, method):\n",
    "        self.method = method\n",
    "        self.filename = filename\n",
    "        self.original = 0.0\n",
    "        self.compressed = 0.0\n",
    "        self.ratio = 1\n",
    "\n",
    "    def get_ratio(self):\n",
    "        pickle_path = f\"{self.filename}.pickle\"\n",
    "        file_path = f\"{self.filename}.{self.method}\"\n",
    "\n",
    "        return os.path.getsize(file_path)/os.path.getsize(pickle_path)\n",
    "    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_performance_stats(df):\n",
    "    pivot_table = df.pivot_table(index='algorithm_name', values=['compression_ratio', 'execution_time'], aggfunc='mean')\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    pivot_table['compression_ratio'].plot(kind='bar', ax=ax1, color='b')\n",
    "    ax1.set_ylabel('Compression Ratio', color='b')\n",
    "    ax1.tick_params('y', colors='b')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    pivot_table['execution_time'].plot(kind='line', ax=ax2, color='r', marker='o')\n",
    "    ax2.set_ylabel('Execution Time (seconds)', color='r')\n",
    "    ax2.tick_params('y', colors='r')\n",
    "\n",
    "    ax1.set_xlabel('Algorithm Name')\n",
    "    ax1.set_title('Compression Ratio and Execution Time by Algorithm')\n",
    "\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "data = {'compression_ratio': [\n",
    "            PerformanceStats('../data/customers-100000', 'gzip').get_ratio(),\n",
    "            PerformanceStats('../data/customers-100000', 'pbz2').get_ratio(), \n",
    "            PerformanceStats('../data/customers-100000', 'blosc2').get_ratio()],\n",
    "        'execution_time': [307, 1270, 174],\n",
    "        'algorithm_name': ['gzip', 'pbz2', 'blosc2']}\n",
    "\n",
    "plot_performance_stats(pandas.DataFrame(data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was an interesting result. \n",
    "\n",
    "blosc2 had best loading time, but worse compression rate\n",
    "\n",
    "pbz2 was twice as efficent for compression, but 10x slower\n",
    "\n",
    "\n",
    "Let's try with a much larger pickle ~3GB\n",
    "https://www.kaggle.com/code/columbia2131/speed-up-reading-csv-to-pickle/input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pandas.read_pickle('../data/ump-train-picklefile/train.pkl')\n",
    "\n",
    "compress_pickle_b2z(\"../data/ump-train-picklefile/train.pbz2\", train)\n",
    "compress_pickle_gzip(\"../data/ump-train-picklefile/train.gzip\", train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pandas.read_pickle('../data/ump-train-picklefile/train.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "src cannot be larger than 2147483615 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m compress_pickle_blosc2(\u001b[39m\"\u001b[39;49m\u001b[39m../data/ump-train-picklefile/train.blosc2\u001b[39;49m\u001b[39m\"\u001b[39;49m, train)\n",
      "Cell \u001b[1;32mIn[1], line 54\u001b[0m, in \u001b[0;36mcompress_pickle_blosc2\u001b[1;34m(file, data)\u001b[0m\n\u001b[0;32m     52\u001b[0m blosc2\u001b[39m.\u001b[39mMAX_BUFFERSIZE \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m\n\u001b[0;32m     53\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m---> 54\u001b[0m     f\u001b[39m.\u001b[39mwrite(blosc2\u001b[39m.\u001b[39;49mcompress(cPickle\u001b[39m.\u001b[39;49mdumps(data)))\n",
      "File \u001b[1;32md:\\pub\\sandbox\\.venv\\lib\\site-packages\\blosc2\\core.py:116\u001b[0m, in \u001b[0;36mcompress\u001b[1;34m(src, typesize, clevel, filter, codec, _ignore_multiple_size)\u001b[0m\n\u001b[0;32m    114\u001b[0m _check_typesize(typesize)\n\u001b[0;32m    115\u001b[0m _check_filter(\u001b[39mfilter\u001b[39m)\n\u001b[1;32m--> 116\u001b[0m _check_input_length(\u001b[39m\"\u001b[39;49m\u001b[39msrc\u001b[39;49m\u001b[39m\"\u001b[39;49m, len_src, typesize, _ignore_multiple_size\u001b[39m=\u001b[39;49m_ignore_multiple_size)\n\u001b[0;32m    117\u001b[0m \u001b[39mreturn\u001b[39;00m blosc2_ext\u001b[39m.\u001b[39mcompress(src, typesize, clevel, \u001b[39mfilter\u001b[39m, codec)\n",
      "File \u001b[1;32md:\\pub\\sandbox\\.venv\\lib\\site-packages\\blosc2\\core.py:32\u001b[0m, in \u001b[0;36m_check_input_length\u001b[1;34m(input_name, input_len, typesize, _ignore_multiple_size)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_input_length\u001b[39m(input_name, input_len, typesize, _ignore_multiple_size\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m input_len \u001b[39m>\u001b[39m blosc2_ext\u001b[39m.\u001b[39mMAX_BUFFERSIZE:\n\u001b[1;32m---> 32\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m cannot be larger than \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m bytes\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (input_name, blosc2_ext\u001b[39m.\u001b[39mMAX_BUFFERSIZE))\n\u001b[0;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _ignore_multiple_size \u001b[39mand\u001b[39;00m input_len \u001b[39m%\u001b[39m typesize \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     34\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mlen(\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) can only be a multiple of typesize (\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (input_name, typesize))\n",
      "\u001b[1;31mValueError\u001b[0m: src cannot be larger than 2147483615 bytes"
     ]
    }
   ],
   "source": [
    "\n",
    "compress_pickle_blosc2(\"../data/ump-train-picklefile/train.blosc2\", train.to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
